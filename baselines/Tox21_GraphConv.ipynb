{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Tox21_GraphConv.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nihal-rao/deepchem/blob/master/baselines/Tox21_GraphConv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW-q4kpKnwm6"
      },
      "source": [
        "##Installing DeepChem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-oJ-S0HkyYF"
      },
      "source": [
        "DeepChem is a python-based open source deep learning framework and offers feature rich set toolchain that democratizes the use of deep-learning in drug discovery, materials science, quantum chemistry, and biology."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glV7StXjjzt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f805688f-4852-4e20-aa83-f814fa178bd5"
      },
      "source": [
        "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
        "import conda_installer\n",
        "conda_installer.install()\n",
        "!/root/miniconda/bin/conda info -e"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3501  100  3501    0     0  32719      0 --:--:-- --:--:-- --:--:-- 32719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "add /root/miniconda/lib/python3.7/site-packages to PYTHONPATH\n",
            "python version: 3.7.10\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "installing miniconda to /root/miniconda\n",
            "done\n",
            "installing rdkit, openmm, pdbfixer\n",
            "added conda-forge to channels\n",
            "added omnia to channels\n",
            "done\n",
            "conda packages installation finished!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                  *  /root/miniconda\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KKw4cFnkxFw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo9dHE2sjzuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9f97c8-b747-4900-a801-b78a0e33a995"
      },
      "source": [
        "!pip install --pre deepchem"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepchem\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/7f/3f678587e621d1b904ed6d1af65e353b1d681d6b9f4ffaf243c79745c654/deepchem-2.6.0.dev20210403043508-py3-none-any.whl (552kB)\n",
            "\r\u001b[K     |▋                               | 10kB 17.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 20.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 25.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40kB 28.0MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 22.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61kB 24.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 71kB 23.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 81kB 21.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 92kB 20.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 102kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 112kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 122kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 133kB 21.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 143kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 163kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 174kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 184kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 194kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 204kB 21.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 215kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 225kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 235kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 245kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 256kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 266kB 21.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 276kB 21.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 286kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 296kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 307kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 317kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 327kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 337kB 21.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 348kB 21.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 358kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 368kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 378kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 389kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 399kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 409kB 21.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 419kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 430kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 440kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 450kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 460kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 471kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 481kB 21.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 491kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 501kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 512kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 522kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 532kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 542kB 21.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 552kB 21.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Installing collected packages: deepchem\n",
            "Successfully installed deepchem-2.6.0.dev20210403043508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4N2Z66vjzuY"
      },
      "source": [
        "We can now import the `deepchem` package to play with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmQXbIX0jzuZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7b604ff-efa8-4706-d078-c839159a4f40"
      },
      "source": [
        "import deepchem as dc\n",
        "dc.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0.dev'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gosLgS7Zjzuh"
      },
      "source": [
        "## Baseline - Fingerprints + NN\n",
        "\n",
        "Implementing and recording the baseline for Tox21 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-pWelLHjzui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e562e0-3319-4137-8592-7f412a179a04"
      },
      "source": [
        "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='GraphConv')\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "print(train_dataset)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<DiskDataset X.shape: (6264,), y.shape: (6264, 12), w.shape: (6264, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSmQ-U6Xjzup"
      },
      "source": [
        "The graph convolution model similar to a recurrent neural network in which the set of descriptors per atom is updated with each iteration based on those of its neighbours. The final layer is a fully connected layer which predicts output in a multi task setting.\n",
        "\n",
        "The graph convolutions start with a set of descriptiors, it then combines and recombines over various convolutional layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w0OhPYzjzu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9bf0c3-cee8-43a4-fcf4-e89d93f68a58"
      },
      "source": [
        "tasks"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NR-AR',\n",
              " 'NR-AR-LBD',\n",
              " 'NR-AhR',\n",
              " 'NR-Aromatase',\n",
              " 'NR-ER',\n",
              " 'NR-ER-LBD',\n",
              " 'NR-PPAR-gamma',\n",
              " 'SR-ARE',\n",
              " 'SR-ATAD5',\n",
              " 'SR-HSE',\n",
              " 'SR-MMP',\n",
              " 'SR-p53']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "denSanJbtVcS"
      },
      "source": [
        "Above are the tasks in the Tox21 dataset - there are 12 tasks, each corresponding to different biotoxicity targets, such as cell receptors and stress response pathways."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfOwqhtAjzvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0518d787-a2d9-42fe-ca41-fc41e9a81a8c"
      },
      "source": [
        "datasets[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DiskDataset X.shape: (6264,), y.shape: (6264, 12), w.shape: (6264, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJrGU39bwDXY"
      },
      "source": [
        "There are three dataset objects - train split, val split and test split. Each split consists of X and y. X is the features and y is the output label. \n",
        "\n",
        "For example the train split has X.shape (6264, ) and y.shape (6264, 12). This implies that there are 6264 samples in the train split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg-thg7gwhY4"
      },
      "source": [
        "##Training a Model on Fingerprints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C0c1jW-wb9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308b9b48-db37-4527-9433-555027a952af"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "n_tasks = len(tasks)\n",
        "model = dc.models.GraphConvModel(n_tasks, mode='classification')\n",
        "model.fit(train_dataset, nb_epoch=50)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2773268127441406"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjOro0o0xA08"
      },
      "source": [
        "The GraphConv method is based on Duvenaud et al., . It uses a graph convolution model similar to a recurrent neural network in which the set of descriptors per atom is updated with each iteration based on those of its neighbours. The final layer is a fully connected layer which predicts output in a multi task setting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUaR0A5HxsQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fff3773-d434-4b6d-c22a-5d88f3dfdd2f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
        "print('training set score:', model.evaluate(train_dataset, [metric], transformers))\n",
        "print('test set score:', model.evaluate(test_dataset, [metric], transformers))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set score: {'roc_auc_score': 0.9725301575583809}\n",
            "test set score: {'roc_auc_score': 0.7081477950456065}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xesI98ChyhdV"
      },
      "source": [
        "The training set score is much higher than test set score. This indicates overfitting - and is why metrics on the validation set need to be measured in otder to tune parameters and detect overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "456Atrv9o5kz",
        "outputId": "e187a566-8ca6-4171-84a4-ed56ad53ade7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(test_dataset.ids[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@H]1C(=O)O.CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@H]1C(=O)O.c1ccc(CNCCNCc2ccccc2)cc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Inz38_3pA2W",
        "outputId": "1dabf53d-8f72-44d3-ec07-3b116a93c246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(test_dataset.y[0])\n",
        "model.predict(test_dataset)[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.9777729e-01, 8.0222273e-01],\n",
              "       [9.0129119e-01, 9.8708786e-02],\n",
              "       [8.1991351e-01, 1.8008654e-01],\n",
              "       [9.3443751e-01, 6.5562524e-02],\n",
              "       [8.3893728e-01, 1.6106269e-01],\n",
              "       [9.9980229e-01, 1.9778100e-04],\n",
              "       [9.9659061e-01, 3.4094481e-03],\n",
              "       [7.5596905e-01, 2.4403101e-01],\n",
              "       [9.9961579e-01, 3.8413037e-04],\n",
              "       [9.9699223e-01, 3.0077701e-03],\n",
              "       [9.5980692e-01, 4.0193070e-02],\n",
              "       [9.9769384e-01, 2.3061496e-03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjFeWtZQpW8i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}