{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of 04_Introduction_to_Graph_Convolutions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubFUlqz8cj1L"
      },
      "source": [
        "# Tutorial Part 6: Introduction to Graph Convolutions\n",
        "\n",
        "In this tutorial we will learn more about \"graph convolutions.\" These are one of the most powerful deep learning tools for working with molecular data. The reason for this is that molecules can be naturally viewed as graphs.\n",
        "\n",
        "![Molecular Graph](https://github.com/deepchem/deepchem/blob/master/examples/tutorials/basic_graphs.gif?raw=1)\n",
        "\n",
        "Note how standard chemical diagrams of the sort we're used to from high school lend themselves naturally to visualizing molecules as graphs. In the remainder of this tutorial, we'll dig into this relationship in significantly more detail. This will let us get a deeper understanding of how these systems work.\n",
        "\n",
        "## Colab\n",
        "\n",
        "This tutorial and the rest in this sequence are designed to be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/06_Introduction_to_Graph_Convolutions.ipynb)\n",
        "\n",
        "## Setup\n",
        "\n",
        "To run DeepChem within Colab, you'll need to run the following installation commands. This will take about 5 minutes to run to completion and install your environment. You can of course run this tutorial locally if you prefer. In that case, don't run these cells since they will download and install Anaconda on your local machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoCLxSnBcj1N",
        "outputId": "d20c0b59-a8f0-4541-9e7c-9b3f1bfe5334"
      },
      "source": [
        "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
        "import conda_installer\n",
        "conda_installer.install()\n",
        "!/root/miniconda/bin/conda info -e"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3501  100  3501    0     0  14834      0 --:--:-- --:--:-- --:--:-- 14772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "add /root/miniconda/lib/python3.7/site-packages to PYTHONPATH\n",
            "python version: 3.7.10\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "installing miniconda to /root/miniconda\n",
            "done\n",
            "installing rdkit, openmm, pdbfixer\n",
            "added omnia to channels\n",
            "added conda-forge to channels\n",
            "done\n",
            "conda packages installation finished!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                  *  /root/miniconda\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jv2cmnW91CF",
        "outputId": "cc120037-6626-4112-8847-821892a0d90a"
      },
      "source": [
        "!pip install --pre deepchem"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepchem\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/e3/4e96fcaa9cbd282f95b4db9b1d89cde50692c80e482e81f52f2c70d77a6a/deepchem-2.5.0.dev20210309230035-py3-none-any.whl (552kB)\n",
            "\r\u001b[K     |▋                               | 10kB 22.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 29.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 25.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40kB 28.3MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 26.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61kB 29.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 71kB 24.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 81kB 25.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 92kB 26.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 102kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 112kB 28.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 122kB 28.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 133kB 28.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 143kB 28.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153kB 28.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 163kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 174kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 184kB 28.2MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 194kB 28.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 204kB 28.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 215kB 28.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 225kB 28.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 235kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 245kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 256kB 28.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 266kB 28.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 276kB 28.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 286kB 28.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 296kB 28.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 307kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 317kB 28.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 327kB 28.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 337kB 28.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 348kB 28.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 358kB 28.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 368kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 378kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 389kB 28.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 399kB 28.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 409kB 28.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 419kB 28.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 430kB 28.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 440kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 450kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 460kB 28.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 471kB 28.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 481kB 28.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 491kB 28.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 501kB 28.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 512kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 522kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 532kB 28.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 542kB 28.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 552kB 28.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Installing collected packages: deepchem\n",
            "Successfully installed deepchem-2.5.0.dev20210309230035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX2erW0ncj1W"
      },
      "source": [
        "# What are Graph Convolutions?\n",
        "\n",
        "Consider a standard convolutional neural network (CNN) of the sort commonly used to process images.  The input is a grid of pixels.  There is a vector of data values for each pixel, for example the red, green, and blue color channels.  The data passes through a series of convolutional layers.  Each layer combines the data from a pixel and its neighbors to produce a new data vector for the pixel.  Early layers detect small scale local patterns, while later layers detect larger, more abstract patterns.  Often the convolutional layers alternate with pooling layers that perform some operation such as max or min over local regions.\n",
        "\n",
        "Graph convolutions are similar, but they operate on a graph.  They begin with a data vector for each node of the graph (for example, the chemical properties of the atom that node represents).  Convolutional and pooling layers combine information from connected nodes (for example, atoms that are bonded to each other) to produce a new data vector for each node.\n",
        "\n",
        "# Training a GraphConvModel\n",
        "\n",
        "Let's use the MoleculeNet suite to load the Tox21 dataset. To featurize the data in a way that graph convolutional networks can use, we set the featurizer option to `'GraphConv'`. The MoleculeNet call returns a training set, a validation set, and a test set for us to use. It also returns `tasks`, a list of the task names, and `transformers`, a list of data transformations that were applied to preprocess the dataset. (Most deep networks are quite finicky and require a set of data transformations to ensure that training proceeds stably.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMi2V8Jncj1W",
        "outputId": "0c9a25ac-bf5a-4608-dc52-1df1f2a36454"
      },
      "source": [
        "import deepchem as dc\n",
        "\n",
        "tasks, datasets, transformers = dc.molnet.load_lipo(featurizer='GraphConv')\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "print(tasks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['exp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfMW0Y4Kcj1Z"
      },
      "source": [
        "Let's now train a graph convolutional network on this dataset. DeepChem has the class `GraphConvModel` that wraps a standard graph convolutional architecture underneath the hood for user convenience. Let's instantiate an object of this class and train it on our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9n3jTNHcj1a",
        "outputId": "0b111770-0d97-495c-cb1c-3526519162fd"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "n_tasks = len(tasks)\n",
        "model = dc.models.GraphConvModel(n_tasks, mode='regression')\n",
        "model.fit(train_dataset, nb_epoch=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDDroutEcj1g"
      },
      "source": [
        "Let's try to evaluate the performance of the model we've trained. For this, we need to define a metric, a measure of model performance. `dc.metrics` holds a collection of metrics already. For this dataset, it is standard to use the Pearson_r2_score, the area under the receiver operating characteristic curve (which measures the tradeoff between precision and recall). Luckily, the Pearson_r2_score is already available in DeepChem. \n",
        "\n",
        "To measure the performance of the model under this metric, we can use the convenience function `model.evaluate()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeX-9RNWcj1h",
        "outputId": "23c96062-0756-47d6-936d-57f8fbb5665b"
      },
      "source": [
        "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
        "print('Training set score:', model.evaluate(train_dataset, [metric], transformers))\n",
        "print('Test set score:', model.evaluate(test_dataset, [metric], transformers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: {'pearson_r2_score': 0.9427009359280701}\n",
            "Test set score: {'pearson_r2_score': 0.4597287714770163}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-LBxrKN6CMs"
      },
      "source": [
        "The results are pretty good, and `GraphConvModel` is very easy to use. But what's going on under the hood? Could we build GraphConvModel ourselves? Of course! DeepChem provides Keras layers for all the calculations involved in a graph convolution. We are going to apply the following layers from DeepChem.\n",
        "\n",
        "-  `GraphConv` layer: This layer implements the graph convolution. The graph convolution combines per-node feature vectures in a nonlinear fashion with the feature vectors for neighboring nodes.  This \"blends\" information in local neighborhoods of a graph.\n",
        "\n",
        "- `GraphPool` layer: This layer does a max-pooling over the feature vectors of atoms in a neighborhood. You can think of this layer as analogous to a max-pooling layer for 2D convolutions but which operates on graphs instead. \n",
        "\n",
        "- `GraphGather`: Many graph convolutional networks manipulate feature vectors per graph-node. For a molecule for example, each node might represent an atom, and the network would manipulate atomic feature vectors that summarize the local chemistry of the atom. However, at the end of the application, we will likely want to work with a molecule level feature representation. This layer creates a graph level feature vector by combining all the node-level feature vectors.\n",
        "\n",
        "Apart from this we are going to apply standard neural network layers such as [Dense](https://keras.io/api/layers/core_layers/dense/), [BatchNormalization](https://keras.io/api/layers/normalization_layers/batch_normalization/) and [Softmax](https://keras.io/api/layers/activation_layers/softmax/) layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71_E0CAUcj1n"
      },
      "source": [
        "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "class MyGraphConvModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyGraphConvModel, self).__init__()\n",
        "    self.gc1 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
        "    self.batch_norm1 = layers.BatchNormalization()\n",
        "    self.gp1 = GraphPool()\n",
        "\n",
        "    self.gc2 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
        "    self.batch_norm2 = layers.BatchNormalization()\n",
        "    self.gp2 = GraphPool()\n",
        "\n",
        "    self.dense1 = layers.Dense(256, activation=tf.nn.tanh)\n",
        "    self.batch_norm3 = layers.BatchNormalization()\n",
        "    self.readout = GraphGather(batch_size=batch_size, activation_fn=tf.nn.tanh)\n",
        "\n",
        "    self.dense2 = layers.Dense(n_tasks*2)\n",
        "    self.logits = layers.Reshape((n_tasks, 2))\n",
        "    self.softmax = layers.Softmax()\n",
        "\n",
        "  def call(self, inputs):\n",
        "    gc1_output = self.gc1(inputs)\n",
        "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
        "    gp1_output = self.gp1([batch_norm1_output] + inputs[1:])\n",
        "\n",
        "    gc2_output = self.gc2([gp1_output] + inputs[1:])\n",
        "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
        "    gp2_output = self.gp2([batch_norm2_output] + inputs[1:])\n",
        "\n",
        "    dense1_output = self.dense1(gp2_output)\n",
        "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
        "    readout_output = self.readout([batch_norm3_output] + inputs[1:])\n",
        "\n",
        "    logits_output = self.logits(self.dense2(readout_output))\n",
        "    return self.softmax(logits_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC20PZiccj1p"
      },
      "source": [
        "We can now see more clearly what is happening.  There are two convolutional blocks, each consisting of a `GraphConv`, followed by batch normalization, followed by a `GraphPool` to do max pooling.  We finish up with a dense layer, another batch normalization, a `GraphGather` to combine the data from all the different nodes, and a final dense layer to produce the global output. \n",
        "\n",
        "Let's now create the DeepChem model which will be a wrapper around the Keras model that we just created. We will also specify the loss function so the model know the objective to minimize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31Wr0t2zcj1q"
      },
      "source": [
        "model = dc.models.KerasModel(MyGraphConvModel(), loss=dc.models.losses.CategoricalCrossEntropy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz43oG9rcj1j"
      },
      "source": [
        "What are the inputs to this model?  A graph convolution requires a complete description of each molecule, including the list of nodes (atoms) and a description of which ones are bonded to each other.  In fact, if we inspect the dataset we see that the feature array contains Python objects of type `ConvMol`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDvTlErU_OaF",
        "outputId": "1e7c44cb-813a-4d64-fda0-2e343b362c08"
      },
      "source": [
        "test_dataset.X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<deepchem.feat.mol_graphs.ConvMol at 0x7fc3060f6e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbxZr7hE_OaI"
      },
      "source": [
        "Models expect arrays of numbers as their inputs, not Python objects.  We must convert the `ConvMol` objects into the particular set of arrays expected by the `GraphConv`, `GraphPool`, and `GraphGather` layers.  Fortunately, the `ConvMol` class includes the code to do this, as well as to combine all the molecules in a batch to create a single set of arrays.\n",
        "\n",
        "The following code creates a Python generator that given a batch of data generates the lists of inputs, labels, and weights whose values are Numpy arrays. `atom_features` holds a feature vector of length 75 for each atom. The other inputs are required to support minibatching in TensorFlow. `degree_slice` is an indexing convenience that makes it easy to locate atoms from all molecules with a given degree. `membership` determines the membership of atoms in molecules (atom `i` belongs to molecule `membership[i]`). `deg_adjs` is a list that contains adjacency lists grouped by atom degree. For more details, check out the [code](https://github.com/deepchem/deepchem/blob/master/deepchem/feat/mol_graphs.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-cPAG0I8Tc4"
      },
      "source": [
        "from deepchem.metrics import to_one_hot\n",
        "from deepchem.feat.mol_graphs import ConvMol\n",
        "import numpy as np\n",
        "\n",
        "def data_generator(dataset, epochs=1):\n",
        "  for ind, (X_b, y_b, w_b, ids_b) in enumerate(dataset.iterbatches(batch_size, epochs,\n",
        "                                                                   deterministic=False, pad_batches=True)):\n",
        "    multiConvMol = ConvMol.agglomerate_mols(X_b)\n",
        "    inputs = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
        "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
        "      inputs.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
        "    labels = [to_one_hot(y_b.flatten(), 2).reshape(-1, n_tasks, 2)]\n",
        "    weights = [w_b]\n",
        "    yield (inputs, labels, weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSTbjm9Hcj1v"
      },
      "source": [
        "Now, we can train the model using `fit_generator(generator)` which will use the generator we've defined to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "59WW4rhwcj1w",
        "outputId": "72cc4203-44f3-49f9-eadb-275a96a02a1d"
      },
      "source": [
        "model.fit_generator(data_generator(train_dataset, epochs=50))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7ddcc6c2224b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;31m# Main training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_training_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-901c7b5a7035>\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiConvMol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_deg_adjacency_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiConvMol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_deg_adjacency_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mto_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepchem/metrics/metric.py\u001b[0m in \u001b[0;36mto_one_hot\u001b[0;34m(y, n_classes)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y must be a vector of shape (N,) or (N, 1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has more than n_class unique elements.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m   \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m   \u001b[0my_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y has more than n_class unique elements."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skrL9YEEcj13"
      },
      "source": [
        "Now that we have trained our graph convolutional method, let's evaluate its performance. We again have to use our defined generator to evaluate model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "f3prNsgGcj14",
        "scrolled": true,
        "outputId": "b2e74f2e-80e2-49cb-99b4-fcc82a82fc0e"
      },
      "source": [
        "print('Training set score:', model.evaluate_generator(data_generator(train_dataset), [metric], transformers))\n",
        "print('Test set score:', model.evaluate_generator(data_generator(test_dataset), [metric], transformers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8b877fee6a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training set score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test set score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, metrics, transformers, per_task_metrics)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \"\"\"\n\u001b[1;32m    893\u001b[0m     \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeneratorEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_model_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_task_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_saliency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOneOrMany\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepchem/utils/evaluate.py\u001b[0m in \u001b[0;36mcompute_model_performance\u001b[0;34m(self, metrics, per_task_metrics, use_sample_weights, n_classes)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;31m# Process predictions and populate y/w lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;31m# Combine labels/weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mpredict_on_generator\u001b[0;34m(self, generator, transformers, outputs, output_types)\u001b[0m\n\u001b[1;32m    696\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0mproduces\u001b[0m \u001b[0mmultiple\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m     \"\"\"\n\u001b[0;32m--> 698\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m   def predict_on_batch(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, generator, transformers, outputs, uncertainty, other_output_types)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepchem/utils/evaluate.py\u001b[0m in \u001b[0;36mgenerator_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# This is a KerasModel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m           \u001b[0;31m# Some datasets have weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-901c7b5a7035>\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiConvMol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_deg_adjacency_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiConvMol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_deg_adjacency_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mto_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepchem/metrics/metric.py\u001b[0m in \u001b[0;36mto_one_hot\u001b[0;34m(y, n_classes)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y must be a vector of shape (N,) or (N, 1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has more than n_class unique elements.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m   \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m   \u001b[0my_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y has more than n_class unique elements."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvOYgj52cj16"
      },
      "source": [
        "Success! The model we've constructed behaves nearly identically to `GraphConvModel`. If you're looking to build your own custom models, you can follow the example we've provided here to do so. We hope to see exciting constructions from your end soon!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "j1FrVn88cj17"
      },
      "source": [
        "# Congratulations! Time to join the Community!\n",
        "\n",
        "Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n",
        "\n",
        "## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)\n",
        "This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.\n",
        "\n",
        "## Join the DeepChem Gitter\n",
        "The DeepChem [Gitter](https://gitter.im/deepchem/Lobby) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!"
      ]
    }
  ]
}